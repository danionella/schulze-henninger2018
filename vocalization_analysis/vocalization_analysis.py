#! /usr/bin/env python
# -*- coding: utf-8 -*-

"""
Functions to detect acoustic pulses generated by Danionella translucida.

Optimized for Python 2.7
extract_pulses(): analysis a single recording file
+ helper functions
"""

import sys
import os
import shutil
import platform
import argparse
from collections import OrderedDict
import glob
from datetime import datetime, timedelta

import audioio as aio

import numpy as np
import scipy.signal as sig
import scipy.stats as stats

###############################################################################

# parameters for Danionella pulse extractions
check_conditions = dict(max_width=0.008,
                        min_width=0.001,
                        min_size=0.0005,
                        baseline_factor=0.25,
                        max_search_width = 0.2,
                        width_amp_factor=0.15)

def extract_pulses(inpath, max_sec=10*60., highpassf=4000., lowpassf=9000.,
        check_conditions=None, ignore_start=False, debug=False):
    """
    extract pulses from audiofile
    inpath: path of audio file
    max_sec: maximum seconds of data to read
    highpassf = high-pass filter frequency
    lowpassf = low-pass filter frequency
    Returns:
        info: information on the columns in the return data
        all_pulses: numpy array of detected pulses; shape: n x 12
    """

    if check_conditions == None:
        check_conditions = dict(freq=audiodata.samplerate,
                                max_width=0.08,
                                min_width=0.0005,
                                baseline_factor=0.25,
                                max_search_width = 0.2,
                                width_amp_factor=0.15)

    print('## Analyzing file: {0}'.format(inpath))

    # #####################################
    # Pulse detection
    audiodata = aio.AudioLoader(inpath)  # open audiofile
    total_duration = 1.*audiodata.frames/audiodata.samplerate
    rep = time_rep(total_duration)
    print('Duration: {0}'.format(rep))

    check_conditions['freq'] = audiodata.samplerate

    # set start index
    if ignore_start:
        tstart = 20.
        # ignore the first tstart seconds
        cinx = tstart*audiodata.samplerate
    else:
        cinx = 0

    # ITERATE THROUGH THE AUDIO FILE
    info = None
    all_pulses = list()
    maxn = int(max_sec*audiodata.samplerate)  # seconds*samples
    for cinx in xrange(0, audiodata.shape[0], maxn):

        readn = np.min([maxn, audiodata.shape[0]-cinx])
        data = audiodata[cinx:cinx+readn,:]
        # handle multi-channel data by averaging
        data = data if data.shape[1] < 2 else np.mean(data, axis=1)
        tvec = np.arange(cinx, cinx+len(data), dtype=float)/audiodata.samplerate
        
        print('length of data-chunk: {0}').format(time_rep(len(data)/audiodata.samplerate))

        # temporal filtering
        data = highpass_filter(audiodata.samplerate, data, highpassf, order=5)
        data = lowpass_filter(audiodata.samplerate, data, lowpassf, order=5)
        # calculate envelope
        env = envelope(audiodata.samplerate, data, window_size=0.0015, gauss=True)  

        signal_thresh = estimate_noisefloor(env)  # estimate signal threshold
        check_conditions['min_peak_amp'] = signal_thresh
        print('Signal threshold at: {:.5f}'.format(signal_thresh))

        info, pulses = pulse_detector(tvec, env, check_conditions=check_conditions)  # event detector
        if len(pulses):
            print('{0} pulses detected.\n'.format(pulses.shape[0]))
            all_pulses.append(pulses)
        else:
            print('{0} pulses detected.\n'.format(len(pulses)))

    audiodata.close()
    all_pulses = np.vstack(all_pulses) if len(all_pulses) else []
    return info, all_pulses

###############################################################################
# ANALYSIS HELPERS

def estimate_noisefloor(data, perc=90, factor=1.):
    # estimate noise floor:
    noise_floor = np.median(data)
    ne = factor*noise_floor
    print('noise floor estimate: {:.5f}'.format(ne))
    return ne

def clean_up_bursts(bursts):
    """
    Recordings often contain artefacts: a pulse will often be followed by a small after-pulse.
    This function helps to remove most these artefacts.
    """

    # FOR EACH BOUT
    clean_bursts = list()
    removed = list()
    for k, burst in enumerate(bursts):

        peaks = burst[:,2]  # peak value
        goodiesx, baddiesx = separate_good_pulses(peaks)
        goodies = burst[goodiesx]
        baddies = burst[baddiesx]
        print('Bout No. {}: good={}, bad={}'.format(k, len(goodies), len(baddies)))

        clean_bursts.append(goodies)
        removed.append(baddies)
    return clean_bursts, removed

def separate_good_pulses(peaks, n=5, f=0.33, tf=0.33):
    """
    Helper function for "clean_up_bursts"
    The amplitude of pulses within a sequence vary only slowly. this function uses this feature to select only those pulses which sequential amplitudes vary slowly by applying a running window with length n pulses that calculates the mean amplitude of the f fraction of pulses with the strongest amplitude. All pulses with less than tf fraction of this mean amplitude are separated into the 'bad' list.
    Input:
    peakamps = array of the amplitudes of pulses
    n = number of pulses in running analysis window
    f = fraction of peaks that should be used as reference
    tf = fraction of amplitude: good pulses are larger than this
    Returns: indeces of good pulses, indeces of bad pulses
    """
    goodiesx = set()
    baddiesx = set()

    # RUNNING PEAK SELECTION
    nfrac = int(np.ceil(n*f))
    for i in xrange(len(peaks)):
        ps = peaks[i:i+n]  # selection of pulses within burst
        thresh = np.mean(np.sort(ps)[-nfrac:])*tf  # mean of strongest pulses
        inx = ps > thresh
        goodiesx.update(i+np.where(inx)[0])
        baddiesx.update(i+np.where(np.invert(inx))[0])
        # break condition: stop when all pulses have been examined
        if ps.size < n:
            break
    return list(goodiesx), list(baddiesx)

def find_bursts(pulsetimes, cutoff_interval=0.025):
    """
    Function for identifying burst, based on cutoff_interval
    pulsetimes: array of pulsetimes
    cutoff_interval: time between bursts, in seconds
    """
    interval = np.diff(pulsetimes)
    # find gaps between bursts
    gaps = np.where(interval > cutoff_interval)[0]
    # extend by start and end
    bout_inx = np.hstack([[0], gaps+1, [len(pulsetimes)]])
    # burst-length
    bout_l = np.diff(bout_inx)
    print('Number of bursts found: {}'.format(len(bout_l)))
    return bout_inx


###############################################################################
# GENERAL HELPERS

def envelope(rate, data, window_size=0.0015, gauss=False):
    print('generating envelope (t={:.3f}s) ...'.format(window_size))
    from scipy.signal import gaussian

    rstd_window_size_time = window_size  # s
    rstd_window_size = int(rstd_window_size_time * rate)
    # define kernel shape
    if gauss:
        w = 1.0 * gaussian(rstd_window_size, std=rstd_window_size/7)
    else:
        w = 1.0 * np.ones(rstd_window_size)
    w /= np.sum(w)
    rstd = (np.sqrt((np.correlate(data ** 2, w, mode='same') -
                     np.correlate(data, w, mode='same') ** 2)).ravel()) * np.sqrt(2.)
    return rstd

def highpass_filter(rate, data, cutoff, order=3, verbose=True):
    print('highpass ...')
    data = data.ravel()
    nyq = 0.5*rate
    high = cutoff/nyq
    b, a = sig.butter( 4, high, btype='highpass' )
    # plot filter function, with matplotlib
    ## w, h = sig.freqz(b, a)
    ## plt.semilogx(w, 20 * np.log10(abs(h)))
    ## plt.show()
    for o in xrange(order):
        fdata = sig.lfilter( b, a, data )
    return fdata

def lowpass_filter(rate, data, cutoff, order=3, verbose=True) :
    print('lowpass ...')
    data = data.ravel()
    nyq = 0.5*rate
    low = cutoff/nyq
    b, a = sig.butter( 4, low, btype='lowpass' )
    # plot filter function, with matplotlib
    ## w, h = sig.freqz(b, a)
    ## plt.semilogx(w, 20 * np.log10(abs(h)))
    ## plt.show()
    for o in xrange(order):
        fdata = sig.filtfilt(b, a, data)
    return fdata

###############################################################################
# EVENT DETECTION

def pulse_detector(t, data, check_conditions=None):
    print('detecting pulses ... ')
    n = len(data)
    threshold = 0.0001
    info, all_peaks = detect_peaks(t, data, threshold, 
        check_func=accept_peaks, check_conditions=check_conditions)
    return info, all_peaks


def detect_peaks( time, data, threshold, check_func=None, check_conditions=None):
    """
    Peak detection algorithm based on 
    Todd B, Andrews D (1999) The identification of peaks in physiological signals. Comput Biomed Res 32:322â€“335.
    """
    if not check_conditions:
        check_conditions = dict()
        
    event_list = list()

    info = list()  # dummy for returning data on detected events

    # initialize:
    dir = 0
    min_inx = 0
    max_inx = 0
    min_value = data[0]
    max_value = min_value
    trough_inx = 0

    # loop through the new read data
    for index, value in enumerate(data):

        # rising?
        if dir > 0:
            # if the new value is bigger than the old maximum: set it as new maximum
            if max_value < value:
                max_inx = index  # maximum element
                max_value = value

            # otherwise, if the maximum value is bigger than the new value plus the threshold:
            # this is a local maximum!
            elif max_value >= value + threshold:
                # there was a peak:
                event_inx = max_inx

                # check and update event with this magic function
                if check_func:
                    info, r = check_func( time, data, event_inx, index, trough_inx, min_inx, threshold, check_conditions)
                    if len( r ) > 0 :
                        # this really is an event:
                        event_list.append( r )
                else:
                    # this really is an event:
                    event_list.append( time[event_inx] )

                # change direction:
                min_inx = index  # minimum element
                min_value = value
                dir = -1

        # falling?
        elif dir < 0:
            if value < min_value:
                min_inx = index  # minimum element
                min_value = value
                trough_inx = index

            elif value >= min_value + threshold:
                # there was a trough:
                # change direction:
                max_inx = index  # maximum element
                max_value = value
                dir = 1

        # don't know!
        else:
            if max_value >= value + threshold:
                dir = -1  # falling
            elif value >= min_value + threshold:
                dir = 1  # rising

            if max_value < value:
                max_inx = index  # maximum element
                max_value = value

            elif value < min_value:
                min_inx = index  # minimum element
                min_value = value
                trough_inx = index
    data = np.array(event_list) if len(event_list) else []
    return info, data

def accept_peaks(x, data, peak_inx, index, through_inx, min_inx, threshold, check_conditions):
    """
    Accept each detected peak and compute its size and width.

    Args:
        x (array): time, frequency, ... ?
        data (array): the data
        peak_inx: index of the current peak
        index: current index (first minimum after peak at threshold below)
        through_inx: index of the previous trough
        min_inx: index of previous minimum
        threshold: threshold value
    
    Returns: 
        xval (float): x value of the peak
        yval (float): value of data at the peak)
        size (float): size of the peak (peak minus previous trough)
        width (float): width of the peak at 0.75*size
        count (float): zero
    """

    # data is demeaned, so we can assume that it is centered around 0
    ## -> size is defined as height above 10 percent peak-value
    ## -> width is defined as span of the peak above 10 percent peak-value

    # refuse if the peak is too small
    # if not data[peak_inx] > minimum_value:
    if not data[peak_inx] > check_conditions['min_peak_amp']:
        return None, []

    # refuse tiny bumps
    # refuse if: data[peak_inx] - data[-min_inx] < data[peak_inx]*0.5
    thresh = data[peak_inx]*0.5
    if data[peak_inx] - data[min_inx] < thresh:
        return None, []

    # calculating width
    max_search_width = check_conditions['max_search_width']  # sec
    max_search_inx = int(round(max_search_width * check_conditions['freq']))

    baseline = data[through_inx]
    size = data[peak_inx]-data[through_inx]
    thresh = baseline+check_conditions['width_amp_factor']*size

    # check for minimal size
    if size < check_conditions['min_size']:
        return None, []
    # left side
    locminx = peak_inx
    for k in xrange(peak_inx, max([peak_inx-max_search_inx,0]), -1):
        if data[k] < data[locminx]: locminx = k
        if data[k] <= thresh:
            break
        # break point: if thresh can not reached, take local minimum
        ## note: 1st condition due to non-optimal peak detector that may not be the highest peak 
        elif data[locminx] < data[peak_inx]-size*.3 and data[k] > data[peak_inx]:
            k = data[k:peak_inx].argmin()+k
            break
        elif data[k] > 1.5*data[peak_inx]:
            return None, []
    leftinx = k
    leftx = x[k]
    
    # right side
    locminx = peak_inx
    for k in xrange(peak_inx, min([peak_inx+max_search_inx,len(data)])):
        if data[k] < data[locminx]: locminx = k
        if data[k] <= thresh:
            break
        # break point: if thresh can not reached, take local minimum
        ## note: 1st condition due to non-optimal peak detector that may not be the highest peak 
        elif data[locminx] < data[peak_inx]-size*.3 and data[k] > data[peak_inx]:
            k = data[peak_inx:k].argmin()+peak_inx
            break
        elif data[k] > 1.5*data[peak_inx]:
            return None, []
    rightinx = k
    rightx = x[k]

    # check against some conditions
    width = rightx - leftx
    if np.abs(width) >= check_conditions['max_width'] or \
        np.abs(width) <= check_conditions['min_width']:
        return None, []

    info = ['index of peak', 
            'x-value of peak', 
            'y-value of peak',
            'size of peak',
            'width of peak',
            'first index of peak',
            'x-value of first index of peak',
            'last index of peak',
            'x-value of last index of peak']
    data = peak_inx, x[peak_inx], data[peak_inx], size, width, leftinx, leftx, rightinx, rightx
    return info, data


###############################################################################
###############################################################################
# HELPER FUNCTIONS

def time_rep(duration):
    # more readable representation of recording time
    minute = 60.
    hour = minute * 60.
    day = hour * 24.
    if duration < minute:
        rep = '{:.0f} seconds'.format(duration)
    elif duration < hour:
        m = np.floor(duration / minute)
        sec = np.floor(duration - m*minute)
        rep = '{:02.0f}:{:02.0f} [MM:SS]'.format(m,sec)
    elif duration < day:
        h = np.floor(duration / hour)
        m = np.floor((duration - h*hour) / minute)
        sec = np.floor(duration - h*hour - m*minute)
        rep = '{:02.0f}:{:02.0f}:{:02.0f} [HH:MM:SS]'.format(h,m,sec)
    else:
        d = np.floor(duration / day)
        h = np.floor((duration - d*day) / hour)
        m = np.floor((duration - d*day - h*hour) / minute)
        sec = np.floor(duration - d*day - h*hour - m*minute)
        rep = '{:.0f} days, {:02.0f}:{:02.0f}:{:02.0f} [HH:MM:SS]'.format(d,h,m,sec)
    return rep

###############################################################################

if __name__ == '__main__':
    main()
